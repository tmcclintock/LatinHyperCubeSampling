{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/lhs/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from pyDOE2 import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import flatten, nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tvd.FashionMNIST(root=\"./data/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_ds = tvd.FashionMNIST(root=\"./data/\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=32, num_workers=2)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here: sample the LH for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLDFMNISTClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(FMNISTClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=5, stride=3)  # 5x8x8\n",
    "        self.MP1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 5x4x4\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=5, kernel_size=1, stride=1)  # 5x4x4\n",
    "        self.MP2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 5x2x2\n",
    "        self.fc1 = nn.Linear(5 * 2 * 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.MP1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.MP2(x)\n",
    "        x = flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        loss = F.cross_entropy(self(x), y)\n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "class FMNISTClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(FMNISTClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.conv1(x)\n",
    "        #x = self.MP1(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.MP2(x)\n",
    "        x = flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x  # self.fc2(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        loss = F.cross_entropy(self(x), y)\n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.SGD(self.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | fc1  | Linear | 7 K   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1875 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/lhs/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87:  61%|██████    | 1140/1875 [00:03<00:02, 308.59it/s, loss=0.424, v_num=5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/lhs/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist_model = FMNISTClassifier()\n",
    "trainer = pl.Trainer(progress_bar_refresh_rate=20)\n",
    "trainer.fit(fmnist_model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglrs = [-4, -5, -6]\n",
    "loss_record = {}\n",
    "for loglr in loglrs:\n",
    "    lr = 10**loglr\n",
    "    mom = 0.9\n",
    "    loss_record[(loglr, mom)] = perform_training(lr, mom, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (loglr, mom), losses in loss_record.items():\n",
    "    plt.loglog(np.arange(len(losses))+1, losses, label=loglr)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
